# -*- coding: utf-8 -*-
"""Image Classification using CNN [project].ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jiuwu99iYn9yAyLXDd0ipJRCDIIGG_qu
"""

import pathlib
import numpy as np

#Created a list of class_names from the subdirectory
data_dir = pathlib.Path("/content/drive/MyDrive/Train")
class_names = np.array(sorted([item.name for item in data_dir.glob("*")])) 
class_names = class_names[:] 
print(class_names)

data_dir = pathlib.Path("/content/drive/MyDrive/Test")
class_names_test = np.array(sorted([item.name for item in data_dir.glob("*")])) 
class_names_test = class_names_test[:] 
print(class_names_test)

import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import random
import os

#Function which shows random image from 5 directories for better visualization of how the data looks
def view_random_image(target_dir):
  i = random.randrange(4)
  target_folder = target_dir + class_names[i]
  print(target_folder)

  image = random.sample(os.listdir(target_folder), 1)
  print(image)

  img = mpimg.imread(target_folder + "/" + image[0])
  plt.imshow(img)
  plt.title(class_names[i])
  plt.axis("off"); 

  print("Image shape: ",img.shape) #show the shape of image

#Visualizing the data
view_random_image("/content/drive/MyDrive/Train/")

view_random_image("drive/MyDrive/Test/")

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_dir = "/content/drive/MyDrive/Train"
test_dir = "/content/drive/MyDrive/Test"

# Rescaling and augmenting the data
train_datagen = ImageDataGenerator(rescale=1/255.,
                                   rotation_range=0.2,
                                   zoom_range=0.2,
                                   width_shift_range=0.2,
                                   height_shift_range=0.2,
                                   shear_range=0.2,
                                   horizontal_flip=True)

test_datagen = ImageDataGenerator(rescale=1/255.)

# Loading data from directories and turning them into batches
train_data = train_datagen.flow_from_directory(train_dir, target_size=(224, 224))
test_data = test_datagen.flow_from_directory(test_dir, target_size=(224, 224))

model = tf.keras.Sequential([
  tf.keras.layers.Conv2D(filters=10, kernel_size=3, activation="relu", input_shape=(224, 224, 3)),
  tf.keras.layers.MaxPool2D(pool_size=2, padding="valid"),
  tf.keras.layers.Conv2D(filters=10, kernel_size=3, activation="relu"),
  tf.keras.layers.MaxPool2D(pool_size=2),
  tf.keras.layers.Flatten(),
  tf.keras.layers.Dense(5, activation = "softmax")                      
])

model.compile(loss="categorical_crossentropy",
              optimizer=tf.keras.optimizers.Adam(),
              metrics=["accuracy"])

history_1 = model.fit(train_data,
                        epochs=3,
                        steps_per_epoch=len(train_data),
                        validation_data=test_data,
                        validation_steps=len(test_data))

model.evaluate(test_data)